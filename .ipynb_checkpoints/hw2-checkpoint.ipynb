{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4a8d6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5d67ca7d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221.90</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>538.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604.00</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>291.00</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1860</td>\n",
       "      <td>6325</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1860</td>\n",
       "      <td>0</td>\n",
       "      <td>1991</td>\n",
       "      <td>0</td>\n",
       "      <td>47.3492</td>\n",
       "      <td>-122.030</td>\n",
       "      <td>1860</td>\n",
       "      <td>6449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>199.95</td>\n",
       "      <td>2</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1590</td>\n",
       "      <td>20917</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1590</td>\n",
       "      <td>0</td>\n",
       "      <td>1920</td>\n",
       "      <td>0</td>\n",
       "      <td>47.2786</td>\n",
       "      <td>-122.250</td>\n",
       "      <td>1310</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>553.50</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>850</td>\n",
       "      <td>2340</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>1922</td>\n",
       "      <td>0</td>\n",
       "      <td>47.6707</td>\n",
       "      <td>-122.328</td>\n",
       "      <td>1300</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>189.95</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1030</td>\n",
       "      <td>4188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1030</td>\n",
       "      <td>0</td>\n",
       "      <td>1981</td>\n",
       "      <td>0</td>\n",
       "      <td>47.3738</td>\n",
       "      <td>-122.057</td>\n",
       "      <td>1450</td>\n",
       "      <td>3376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>289.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1850</td>\n",
       "      <td>9550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1850</td>\n",
       "      <td>0</td>\n",
       "      <td>1988</td>\n",
       "      <td>0</td>\n",
       "      <td>47.3225</td>\n",
       "      <td>-122.273</td>\n",
       "      <td>2250</td>\n",
       "      <td>9550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  \\\n",
       "0    221.90         3       1.00         1180      5650     1.0           0   \n",
       "1    538.00         3       2.25         2570      7242     2.0           0   \n",
       "2    180.00         2       1.00          770     10000     1.0           0   \n",
       "3    604.00         4       3.00         1960      5000     1.0           0   \n",
       "4    510.00         3       2.00         1680      8080     1.0           0   \n",
       "..      ...       ...        ...          ...       ...     ...         ...   \n",
       "995  291.00         4       2.50         1860      6325     2.0           0   \n",
       "996  199.95         2       2.75         1590     20917     1.5           0   \n",
       "997  553.50         2       1.00          850      2340     1.0           0   \n",
       "998  189.95         2       1.00         1030      4188     1.0           0   \n",
       "999  289.00         3       2.00         1850      9550     1.0           0   \n",
       "\n",
       "     view  condition  grade  sqft_above  sqft_basement  yr_built  \\\n",
       "0       0          3      7        1180              0      1955   \n",
       "1       0          3      7        2170            400      1951   \n",
       "2       0          3      6         770              0      1933   \n",
       "3       0          5      7        1050            910      1965   \n",
       "4       0          3      8        1680              0      1987   \n",
       "..    ...        ...    ...         ...            ...       ...   \n",
       "995     0          4      7        1860              0      1991   \n",
       "996     0          3      5        1590              0      1920   \n",
       "997     0          3      7         850              0      1922   \n",
       "998     0          3      8        1030              0      1981   \n",
       "999     0          3      8        1850              0      1988   \n",
       "\n",
       "     yr_renovated      lat     long  sqft_living15  sqft_lot15  \n",
       "0               0  47.5112 -122.257           1340        5650  \n",
       "1            1991  47.7210 -122.319           1690        7639  \n",
       "2               0  47.7379 -122.233           2720        8062  \n",
       "3               0  47.5208 -122.393           1360        5000  \n",
       "4               0  47.6168 -122.045           1800        7503  \n",
       "..            ...      ...      ...            ...         ...  \n",
       "995             0  47.3492 -122.030           1860        6449  \n",
       "996             0  47.2786 -122.250           1310        6000  \n",
       "997             0  47.6707 -122.328           1300        3000  \n",
       "998             0  47.3738 -122.057           1450        3376  \n",
       "999             0  47.3225 -122.273           2250        9550  \n",
       "\n",
       "[1000 rows x 18 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read training data \n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "df_train = df_train.drop(columns = ['Unnamed: 0', 'zipcode'])\n",
    "df_test = df_test.drop(columns=['Unnamed: 0', 'zipcode', 'date', 'id'])\n",
    "df_train['price'] = df_train['price']/1000\n",
    "df_test['price'] = df_test['price']/1000\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ef036fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features and target\n",
    "x_train = df_train.loc[:,df_train.columns != 'price']\n",
    "y_train = df_train.loc[:, 'price']\n",
    "x_test = df_test.loc[:,df_test.columns != 'price']\n",
    "y_test = df_test.loc[:, 'price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdf482ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data:\n",
      "mean squared error: 31486.16777579488\n",
      "[-12.52196187  18.52763251  56.7488368   10.88186845   8.04372084\n",
      "  63.74289956  48.20010852  12.96426936  92.23147482  48.29008886\n",
      "  27.13703247 -67.64311741  17.27137953  78.37573693  -1.03520308\n",
      "  45.57765781 -12.93009098]\n",
      "model r^2: 0.7265334318706018\n",
      "testing data:\n",
      "mean squared error: 59784.36556751678\n",
      "[-12.52196187  18.52763251  56.7488368   10.88186845   8.04372084\n",
      "  63.74289956  48.20010852  12.96426936  92.23147482  48.29008886\n",
      "  27.13703247 -67.64311741  17.27137953  78.37573693  -1.03520308\n",
      "  45.57765781 -12.93009098]\n",
      "r^2: 0.6414235000248592\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = pd.DataFrame(scaler.fit_transform(x_train), columns=x_train.columns)\n",
    "x_test = pd.DataFrame(scaler.fit_transform(x_test), columns=x_test.columns)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X=x_train, y=y_train)\n",
    "\n",
    "#predict train\n",
    "print(\"training data:\")\n",
    "predict = model.predict(X=x_train)\n",
    "score = model.score(x_train, y_train)\n",
    "mse = mean_squared_error(y_train, predict)\n",
    "#r2 = r2_score(y_train, predict)\n",
    "print(f'mean squared error: {mse}')\n",
    "print(model.coef_)   \n",
    "print (f'model r^2: {score}')\n",
    "\n",
    "\n",
    "#predict test\n",
    "print(\"testing data:\")\n",
    "predict = model.predict(X=x_test)\n",
    "score = model.score(x_test, y_test)\n",
    "mse = mean_squared_error(y_test, predict)\n",
    "print(f'mean squared error: {mse}')\n",
    "print(model.coef_)   \n",
    "print (f'r^2: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "65fc3669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 linear regression\n",
    "from numpy.linalg import inv\n",
    "class MyLinearRegression:\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X_arr = np.insert(X.to_numpy(), 0, 1, axis=1)\n",
    "        y_arr = y.to_numpy()\n",
    "        # we know theta = (X^TX)^-1X^Ty\n",
    "        theta = inv(X_arr.transpose()@X_arr)@(X_arr.transpose()@y)\n",
    "        self.theta = theta\n",
    "        return theta\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_arr = np.insert(X.to_numpy(), 0, 1, axis=1)\n",
    "        return X_arr@self.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "791d9326",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 polynomial regression\n",
    "class PolyRegression:\n",
    "    def __init__(self, p):\n",
    "        self.p = p\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X_arr = np.insert(X.to_numpy(), 0, 1, axis=1)\n",
    "        y_arr = y.to_numpy()\n",
    "        # we know theta = (X^TX)^-1X^Ty\n",
    "        theta = inv(X_arr.transpose()@X_arr)@(X_arr.transpose()@y)\n",
    "        self.theta = theta\n",
    "        return theta\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_orig = X\n",
    "        X_arr = np.insert(X.to_numpy(), 0, 1, axis=1)\n",
    "        for i in range(1, self.p+1):\n",
    "            X_arr = np.append(X_arr, X_orig**i)\n",
    "        return X_arr@self.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4d48606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 gradient descent\n",
    "from numpy.linalg import norm\n",
    "class GradientDescentLR:\n",
    "    def __init__(self, alpha, max_depth):\n",
    "        self.alpha = alpha\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X_arr = X.to_numpy()\n",
    "        y_arr = y.to_numpy()\n",
    "        X_trans = X_arr.transpose()\n",
    "        diff = 10000000\n",
    "        count = 0\n",
    "        theta = np.random.rand(X_arr.shape[1], 1)   \n",
    "        while (diff > self.alpha or count < self.max_depth):\n",
    "            const = alpha * 2/len(X.index)\n",
    "            theta_new = const * X_trans@(X_arr@theta - y_arr)\n",
    "            diff = norm(theta_new - theta)\n",
    "            theta = theta_new\n",
    "            count+=1\n",
    "        self.theta = theta\n",
    "        return theta\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return X@self.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e92ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridge\n",
    "class RidgeRegression:\n",
    "    def __init__(self, cost):\n",
    "        self.cost = cost\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X_arr = np.insert(X.to_numpy(), 0, 1, axis=1)\n",
    "        y_arr = y.to_numpy()\n",
    "        theta = X_arr.transpose@()\n",
    "        self.theta = theta\n",
    "        return theta\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_arr = np.insert(X.to_numpy(), 0, 1, axis=1)\n",
    "        return X_arr@self.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0a0daed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "my_reg = MyLinearRegression()\n",
    "my_reg.fit(x_train, y_train)\n",
    "predict = my_reg.predict(x_test)\n",
    "mse = mean_squared_error(y_train, predict)\n",
    "r2 = r2_score(y_train, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3d98568a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set performance\n",
      "   MSE = 3.0835e+05\n",
      "   R2 = -1.678\n",
      "Testing set performance\n",
      "   MSE = 3.6823e+05\n",
      "   R2 = -1.209\n"
     ]
    }
   ],
   "source": [
    "def run_model(X_train, Y_train, X_test, Y_test, model, print_coef=False):\n",
    "    model.fit(X_train, Y_train)\n",
    "    if print_coef:\n",
    "        print(f'Intercept: {model.intercept_:.2f}')\n",
    "        print('Coefficients\\n', model.coef_)\n",
    "\n",
    "    Y_train_predicted = model.predict(X_train)\n",
    "    mse = mean_squared_error(Y_train, Y_train_predicted)\n",
    "    r2= r2_score(Y_train, Y_train_predicted)\n",
    "\n",
    "    print(\"Training set performance\")\n",
    "    print(f'   MSE = {format_nbr(mse)}')\n",
    "    print(f'   R2 = {format_nbr(r2)}')\n",
    "   \n",
    "    Y_test_predicted = model.predict(X_test)\n",
    "    mse = mean_squared_error(Y_test, Y_test_predicted)\n",
    "    r2= r2_score(Y_test, Y_test_predicted)\n",
    "\n",
    "    print(\"Testing set performance\")\n",
    "    print(f'   MSE = {format_nbr(mse)}')\n",
    "    print(f'   R2 = {format_nbr(r2)}')\n",
    "    \n",
    "# format a number based on its magnitude\n",
    "# If <= 100000, print using :.3f\n",
    "# Else print using :.0e\n",
    "def format_nbr(f):\n",
    "    if abs(f) < 100000:\n",
    "        return f'{f:.3f}'\n",
    "    else:\n",
    "        return f'{f:.4e}'\n",
    "    \n",
    "run_model(x_train, y_train, x_test, y_test, MyLinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4417b660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0             1             2             3             4    \\\n",
      "0   -1.724365e-10 -1.724367e-10 -1.724361e-10 -1.724352e-10 -1.724354e-10   \n",
      "1   -3.462125e-10 -3.462127e-10 -3.462122e-10 -3.462127e-10 -3.462129e-10   \n",
      "2   -3.152131e-10 -3.152129e-10 -3.152131e-10 -3.152134e-10 -3.152134e-10   \n",
      "3    1.428365e-10  1.428361e-10  1.428369e-10  1.428363e-10  1.428361e-10   \n",
      "4   -1.238829e-10 -1.238835e-10 -1.238823e-10 -1.238837e-10 -1.238839e-10   \n",
      "..            ...           ...           ...           ...           ...   \n",
      "995 -3.368365e-10 -3.368361e-10 -3.368364e-10 -3.368361e-10 -3.368370e-10   \n",
      "996 -8.487915e-10 -8.487918e-10 -8.487911e-10 -8.487913e-10 -8.487912e-10   \n",
      "997 -9.593525e-10 -9.593525e-10 -9.593521e-10 -9.593519e-10 -9.593520e-10   \n",
      "998  1.240677e-10  1.240679e-10  1.240674e-10  1.240672e-10  1.240673e-10   \n",
      "999  5.654614e-10  5.654614e-10  5.654616e-10  5.654620e-10  5.654613e-10   \n",
      "\n",
      "              5             6             7             8             9    \\\n",
      "0   -1.724339e-10 -1.724363e-10 -1.724356e-10 -1.724359e-10 -1.724366e-10   \n",
      "1   -3.462138e-10 -3.462124e-10 -3.462126e-10 -3.462121e-10 -3.462120e-10   \n",
      "2   -3.152112e-10 -3.152129e-10 -3.152134e-10 -3.152134e-10 -3.152129e-10   \n",
      "3    1.428344e-10  1.428363e-10  1.428366e-10  1.428367e-10  1.428370e-10   \n",
      "4   -1.238849e-10 -1.238829e-10 -1.238834e-10 -1.238826e-10 -1.238821e-10   \n",
      "..            ...           ...           ...           ...           ...   \n",
      "995 -3.368381e-10 -3.368362e-10 -3.368363e-10 -3.368359e-10 -3.368359e-10   \n",
      "996 -8.487894e-10 -8.487913e-10 -8.487914e-10 -8.487909e-10 -8.487909e-10   \n",
      "997 -9.593497e-10 -9.593519e-10 -9.593521e-10 -9.593517e-10 -9.593519e-10   \n",
      "998  1.240706e-10  1.240675e-10  1.240670e-10  1.240670e-10  1.240674e-10   \n",
      "999  5.654587e-10  5.654612e-10  5.654616e-10  5.654615e-10  5.654614e-10   \n",
      "\n",
      "     ...           990           991           992           993  \\\n",
      "0    ... -1.724359e-10 -1.724338e-10 -1.724350e-10 -1.724363e-10   \n",
      "1    ... -3.462132e-10 -3.462124e-10 -3.462124e-10 -3.462122e-10   \n",
      "2    ... -3.152127e-10 -3.152137e-10 -3.152122e-10 -3.152129e-10   \n",
      "3    ...  1.428350e-10  1.428353e-10  1.428377e-10  1.428367e-10   \n",
      "4    ... -1.238848e-10 -1.238833e-10 -1.238820e-10 -1.238822e-10   \n",
      "..   ...           ...           ...           ...           ...   \n",
      "995  ... -3.368369e-10 -3.368359e-10 -3.368373e-10 -3.368364e-10   \n",
      "996  ... -8.487910e-10 -8.487897e-10 -8.487909e-10 -8.487911e-10   \n",
      "997  ... -9.593514e-10 -9.593494e-10 -9.593526e-10 -9.593519e-10   \n",
      "998  ...  1.240693e-10  1.240671e-10  1.240659e-10  1.240676e-10   \n",
      "999  ...  5.654601e-10  5.654611e-10  5.654624e-10  5.654617e-10   \n",
      "\n",
      "              994           995           996           997           998  \\\n",
      "0   -1.724362e-10 -1.724357e-10 -1.724362e-10 -1.724366e-10 -1.724365e-10   \n",
      "1   -3.462120e-10 -3.462126e-10 -3.462119e-10 -3.462131e-10 -3.462123e-10   \n",
      "2   -3.152128e-10 -3.152130e-10 -3.152130e-10 -3.152134e-10 -3.152127e-10   \n",
      "3    1.428367e-10  1.428364e-10  1.428363e-10  1.428364e-10  1.428371e-10   \n",
      "4   -1.238823e-10 -1.238834e-10 -1.238827e-10 -1.238836e-10 -1.238824e-10   \n",
      "..            ...           ...           ...           ...           ...   \n",
      "995 -3.368360e-10 -3.368365e-10 -3.368359e-10 -3.368363e-10 -3.368363e-10   \n",
      "996 -8.487908e-10 -8.487912e-10 -8.487905e-10 -8.487921e-10 -8.487913e-10   \n",
      "997 -9.593516e-10 -9.593519e-10 -9.593513e-10 -9.593528e-10 -9.593525e-10   \n",
      "998  1.240673e-10  1.240671e-10  1.240675e-10  1.240668e-10  1.240671e-10   \n",
      "999  5.654612e-10  5.654614e-10  5.654610e-10  5.654615e-10  5.654615e-10   \n",
      "\n",
      "              999  \n",
      "0   -1.724361e-10  \n",
      "1   -3.462122e-10  \n",
      "2   -3.152126e-10  \n",
      "3    1.428361e-10  \n",
      "4   -1.238827e-10  \n",
      "..            ...  \n",
      "995 -3.368365e-10  \n",
      "996 -8.487908e-10  \n",
      "997 -9.593514e-10  \n",
      "998  1.240676e-10  \n",
      "999  5.654611e-10  \n",
      "\n",
      "[1000 rows x 1000 columns]\n"
     ]
    }
   ],
   "source": [
    "gd = GradientDescentLR(alpha=.5, max_depth = 10)\n",
    "gd.fit(x_train, y_train)\n",
    "print(gd.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8dcd8808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** alpha = 0.01 max_iter = 10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred have different number of output (1!=1000)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-3986455501f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'**** alpha ='\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"max_iter =\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mrun_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGradientDescentLR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_coef\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-77-93b58b4d4a00>\u001b[0m in \u001b[0;36mrun_model\u001b[1;34m(X_train, Y_train, X_test, Y_test, model, print_coef)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mY_train_predicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train_predicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mr2\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train_predicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[1;36m0.825\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \"\"\"\n\u001b[1;32m--> 335\u001b[1;33m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[0;32m    336\u001b[0m         y_true, y_pred, multioutput)\n\u001b[0;32m    337\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         raise ValueError(\"y_true and y_pred have different number of output \"\n\u001b[0m\u001b[0;32m    100\u001b[0m                          \"({0}!={1})\".format(y_true.shape[1], y_pred.shape[1]))\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y_true and y_pred have different number of output (1!=1000)"
     ]
    }
   ],
   "source": [
    "for alpha in [0.01, 0.1, 0.5]:\n",
    "    for max_iter in [10, 50, 100]:\n",
    "        print('**** alpha =', alpha, \"max_iter =\", max_iter)\n",
    "        run_model(x_train, y_train, x_test, y_test, GradientDescentLR(alpha=alpha, max_depth = max_iter), print_coef=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02069612",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
