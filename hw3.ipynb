{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "98816da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3a098a60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.142</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.555</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.404</td>\n",
       "      <td>6</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.147</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4601 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0               0.00               0.64           0.64           0.0   \n",
       "1               0.21               0.28           0.50           0.0   \n",
       "2               0.06               0.00           0.71           0.0   \n",
       "3               0.00               0.00           0.00           0.0   \n",
       "4               0.00               0.00           0.00           0.0   \n",
       "...              ...                ...            ...           ...   \n",
       "4596            0.31               0.00           0.62           0.0   \n",
       "4597            0.00               0.00           0.00           0.0   \n",
       "4598            0.30               0.00           0.30           0.0   \n",
       "4599            0.96               0.00           0.00           0.0   \n",
       "4600            0.00               0.00           0.65           0.0   \n",
       "\n",
       "      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0              0.32            0.00              0.00                0.00   \n",
       "1              0.14            0.28              0.21                0.07   \n",
       "2              1.23            0.19              0.19                0.12   \n",
       "3              0.63            0.00              0.31                0.63   \n",
       "4              0.63            0.00              0.31                0.63   \n",
       "...             ...             ...               ...                 ...   \n",
       "4596           0.00            0.31              0.00                0.00   \n",
       "4597           0.00            0.00              0.00                0.00   \n",
       "4598           0.00            0.00              0.00                0.00   \n",
       "4599           0.32            0.00              0.00                0.00   \n",
       "4600           0.00            0.00              0.00                0.00   \n",
       "\n",
       "      word_freq_order  word_freq_mail  ...  char_freq_;   char_freq_(   \\\n",
       "0                0.00            0.00  ...         0.000         0.000   \n",
       "1                0.00            0.94  ...         0.000         0.132   \n",
       "2                0.64            0.25  ...         0.010         0.143   \n",
       "3                0.31            0.63  ...         0.000         0.137   \n",
       "4                0.31            0.63  ...         0.000         0.135   \n",
       "...               ...             ...  ...           ...           ...   \n",
       "4596             0.00            0.00  ...         0.000         0.232   \n",
       "4597             0.00            0.00  ...         0.000         0.000   \n",
       "4598             0.00            0.00  ...         0.102         0.718   \n",
       "4599             0.00            0.00  ...         0.000         0.057   \n",
       "4600             0.00            0.00  ...         0.000         0.000   \n",
       "\n",
       "      char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0             0.0        0.778        0.000        0.000   \n",
       "1             0.0        0.372        0.180        0.048   \n",
       "2             0.0        0.276        0.184        0.010   \n",
       "3             0.0        0.137        0.000        0.000   \n",
       "4             0.0        0.135        0.000        0.000   \n",
       "...           ...          ...          ...          ...   \n",
       "4596          0.0        0.000        0.000        0.000   \n",
       "4597          0.0        0.353        0.000        0.000   \n",
       "4598          0.0        0.000        0.000        0.000   \n",
       "4599          0.0        0.000        0.000        0.000   \n",
       "4600          0.0        0.125        0.000        0.000   \n",
       "\n",
       "      capital_run_length_average  capital_run_length_longest  \\\n",
       "0                          3.756                          61   \n",
       "1                          5.114                         101   \n",
       "2                          9.821                         485   \n",
       "3                          3.537                          40   \n",
       "4                          3.537                          40   \n",
       "...                          ...                         ...   \n",
       "4596                       1.142                           3   \n",
       "4597                       1.555                           4   \n",
       "4598                       1.404                           6   \n",
       "4599                       1.147                           5   \n",
       "4600                       1.250                           5   \n",
       "\n",
       "      capital_run_length_total  spam  \n",
       "0                          278     1  \n",
       "1                         1028     1  \n",
       "2                         2259     1  \n",
       "3                          191     1  \n",
       "4                          191     1  \n",
       "...                        ...   ...  \n",
       "4596                        88     0  \n",
       "4597                        14     0  \n",
       "4598                       118     0  \n",
       "4599                        78     0  \n",
       "4600                        40     0  \n",
       "\n",
       "[4601 rows x 58 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['word_freq_make','word_freq_address', 'word_freq_all','word_freq_3d','word_freq_our','word_freq_over',\n",
    "         'word_freq_remove','word_freq_internet','word_freq_order','word_freq_mail','word_freq_receive','word_freq_will',\n",
    "         'word_freq_people','word_freq_report','word_freq_addresses','word_freq_free','word_freq_business','word_freq_email',\n",
    "         'word_freq_you','word_freq_credit','word_freq_your','word_freq_font','word_freq_000','word_freq_money','word_freq_hp',\n",
    "         'word_freq_hpl','word_freq_george','word_freq_650','word_freq_lab','word_freq_labs','word_freq_telnet','word_freq_857',\n",
    "         'word_freq_data','word_freq_415','word_freq_85','word_freq_technology','word_freq_1999','word_freq_parts','word_freq_pm',\n",
    "         'word_freq_direct','word_freq_cs','word_freq_meeting','word_freq_original','word_freq_project','word_freq_re','word_freq_edu',\n",
    "         'word_freq_table','word_freq_conference','char_freq_; ','char_freq_( ','char_freq_[','char_freq_!','char_freq_$','char_freq_#',\n",
    "        'capital_run_length_average','capital_run_length_longest','capital_run_length_total', 'spam']\n",
    "df = pd.read_csv('spambase.data', names=cols)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8a7a85b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "features = df.loc[:,df.columns != 'spam']\n",
    "target = df.loc[:, 'spam']\n",
    "# Split into training/testing\n",
    "# The following will split as 75% training 25% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.25, random_state=3000)\n",
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3a3c8c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format a number based on its magnitude\n",
    "# If <= 100000, print using :.3f\n",
    "# Else print using :.0e\n",
    "def format_nbr(f):\n",
    "    if abs(f) < 100000:\n",
    "        return f'{f:.3f}'\n",
    "    else:\n",
    "        return f'{f:.4e}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9c09c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1a train logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train, y_train)\n",
    "y_test_predicted = log_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "50224780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   confusion matrix =\n",
      " [[663  39]\n",
      " [ 42 407]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#1a conf matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_test_predicted)\n",
    "print(f'   confusion matrix =\\n {conf_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8861154e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true positives =  407,\n",
      "false positives = 39,\n",
      "true negatives = 663,\n",
      "false negatives = 42\n"
     ]
    }
   ],
   "source": [
    "#1a tn, fp, fn, tp\n",
    "tn, fp, fn, tp = conf_matrix.ravel() \n",
    "print (f'true positives =  {tp},\\nfalse positives = {fp},\\ntrue negatives = {tn},\\nfalse negatives = {fn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "efd40b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy = 0.930\n",
      "   error = 0.070\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#1a acc/error \n",
    "acc = accuracy_score(y_test, y_test_predicted)\n",
    "err = 1-acc\n",
    "print(f'   accuracy = {format_nbr(acc)}')\n",
    "print(f'   error = {format_nbr(err)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b406b0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   precision = 0.913\n",
      "   recall = 0.906\n",
      "   f1 = 0.909\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#1a prec, recall, f1\n",
    "prec= precision_score(y_test, y_test_predicted)\n",
    "recall = recall_score(y_test, y_test_predicted)\n",
    "f1 = f1_score(y_test, y_test_predicted)\n",
    "print(f'   precision = {format_nbr(prec)}')\n",
    "print(f'   recall = {format_nbr(recall)}')\n",
    "print(f'   f1 = {format_nbr(f1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d3be8478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature      Coef\n",
      "55  capital_run_length_longest  1.267732\n",
      "52                 char_freq_$  1.207775\n",
      "6             word_freq_remove  0.895562\n",
      "22               word_freq_000  0.894307\n",
      "3                 word_freq_3d  0.864112\n",
      "53                 char_freq_#  0.858514\n",
      "15              word_freq_free  0.821593\n",
      "19            word_freq_credit  0.569852\n",
      "56    capital_run_length_total  0.443533\n",
      "4                word_freq_our  0.396171\n",
      "16          word_freq_business  0.386323\n",
      "23             word_freq_money  0.361201\n",
      "35        word_freq_technology  0.290619\n",
      "51                 char_freq_!  0.248957\n",
      "27               word_freq_650  0.238475\n",
      "20              word_freq_your  0.237265\n",
      "21              word_freq_font  0.227725\n",
      "5               word_freq_over  0.191943\n",
      "7           word_freq_internet  0.191727\n",
      "8              word_freq_order  0.178446\n",
      "31               word_freq_857  0.162189\n",
      "18               word_freq_you  0.161183\n",
      "14         word_freq_addresses  0.132030\n",
      "17             word_freq_email  0.096326\n",
      "2                word_freq_all  0.077128\n",
      "13            word_freq_report  0.066924\n",
      "9               word_freq_mail  0.062902\n",
      "36              word_freq_1999  0.002406\n",
      "10           word_freq_receive -0.017561\n",
      "12            word_freq_people -0.022277\n",
      "0               word_freq_make -0.062459\n",
      "50                 char_freq_[ -0.069315\n",
      "49                char_freq_(  -0.119270\n",
      "37             word_freq_parts -0.131000\n",
      "11              word_freq_will -0.142506\n",
      "46             word_freq_table -0.178525\n",
      "1            word_freq_address -0.216185\n",
      "29              word_freq_labs -0.236895\n",
      "39            word_freq_direct -0.238364\n",
      "42          word_freq_original -0.287974\n",
      "48                char_freq_;  -0.309355\n",
      "54  capital_run_length_average -0.328625\n",
      "30            word_freq_telnet -0.370172\n",
      "38                word_freq_pm -0.413348\n",
      "32              word_freq_data -0.497956\n",
      "44                word_freq_re -0.732016\n",
      "47        word_freq_conference -0.810440\n",
      "25               word_freq_hpl -0.897575\n",
      "43           word_freq_project -0.925207\n",
      "45               word_freq_edu -1.169913\n",
      "33               word_freq_415 -1.207919\n",
      "34                word_freq_85 -1.251728\n",
      "41           word_freq_meeting -1.297299\n",
      "28               word_freq_lab -1.359462\n",
      "40                word_freq_cs -1.655612\n",
      "24                word_freq_hp -2.277950\n",
      "26            word_freq_george -3.912352\n"
     ]
    }
   ],
   "source": [
    "#1b print coeffs \n",
    "# Make a dataframe with first column naming features and 2nd column the coefficient for that feature\n",
    "d = {'feature': cols[:-1], 'Coef': log_model.coef_[0]}\n",
    "df_coef = pd.DataFrame(data = d)\n",
    "# Sort the coefficient dataframe to see which are largest (both positive and negative)\n",
    "df_coef_sorted = df_coef.sort_values('Coef', ascending=False)\n",
    "print(df_coef_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2de3a900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.898349</td>\n",
       "      <td>0.810861</td>\n",
       "      <td>0.964365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.929626</td>\n",
       "      <td>0.912556</td>\n",
       "      <td>0.906459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.903562</td>\n",
       "      <td>0.947090</td>\n",
       "      <td>0.797327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.847958</td>\n",
       "      <td>0.962838</td>\n",
       "      <td>0.634744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      T  Accuracy  Precision   Recall:\n",
       "0  0.25  0.898349   0.810861  0.964365\n",
       "1  0.50  0.929626   0.912556  0.906459\n",
       "2  0.75  0.903562   0.947090  0.797327\n",
       "3  0.90  0.847958   0.962838  0.634744"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1c\n",
    "probs = log_model.predict_proba(X_test)\n",
    "col_t = []\n",
    "col_acc = []\n",
    "col_prec = []\n",
    "col_recall = []\n",
    "for t in [0.25, 0.5, 0.75, 0.9]:\n",
    "    y_pred_t = np.where(probs[:, 1] >= t, 1, 0)\n",
    "    accuracy = accuracy_score(y_test, y_pred_t)\n",
    "    prec= precision_score(y_test, y_pred_t)\n",
    "    recall = recall_score(y_test, y_pred_t)\n",
    "    col_t.append(t)\n",
    "    col_acc.append(accuracy)\n",
    "    col_prec.append(prec)\n",
    "    col_recall.append(recall)\n",
    "    \n",
    "d = {'T': col_t, 'Accuracy': col_acc, 'Precision': col_prec, 'Recall:' : col_recall}\n",
    "metrics_df = pd.DataFrame(d)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "78119ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 gradient descent\n",
    "from numpy.linalg import norm\n",
    "class LogisticRegressionGD:\n",
    "    def __init__(self, alpha, epsilon = .01, max_iter=1000):\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "        self.max_iter = max_iter\n",
    "        self.theta_ = []\n",
    "    \n",
    "    def h_theta(self, X, theta):\n",
    "        z = X @ theta\n",
    "        # Protect against exp(-z) blowing up and causing a warning\n",
    "        z = np.maximum(-1.0E2, z)\n",
    "        h = 1 / (1 + np.exp(-z))\n",
    "        return h\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X_arr = np.insert(X.to_numpy(), 0, 1, axis=1)\n",
    "        h = self.h_theta(X_arr, self.theta_)\n",
    "        probs = np.zeros(shape=(X_arr.shape[0], 2))\n",
    "        probs[:, 1] = h\n",
    "        probs[:, 0] = 1 - h\n",
    "        return probs\n",
    "\n",
    "\n",
    "    # fits the model to the training data\n",
    "    def fit(self, X, y):\n",
    "        X_arr = np.insert(X.to_numpy(), 0, 1, axis=1)\n",
    "        # Initialize random theta\n",
    "        self.theta_ = np.random.rand(X_arr.shape[1])\n",
    "       \n",
    "        for i in range(0, self.max_iter):\n",
    "            h = self.h_theta(X_arr, self.theta_)\n",
    "            theta_new = self.theta_ - self.alpha * (h - y).transpose() @ X_arr\n",
    "            delta = np.linalg.norm(theta_new - self.theta_)\n",
    "            self.theta_ = theta_new\n",
    "            if delta < self.epsilon:\n",
    "                break\n",
    "        # Save instance variables used by run_model method\n",
    "        self.coef_ = self.theta_[1:]\n",
    "        self.intercept_ = self.theta_[0]\n",
    "\n",
    "    # Predict Y values given X values using model fit\n",
    "    def predict(self, X):\n",
    "        X2 = np.insert(X.to_numpy(), 0, 1, axis=1)\n",
    "        probs = self.h_theta(X2, self.theta_)\n",
    "        result = np.where(probs >= 0.5, 1, 0)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8dca74c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Iterations</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.659877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>0.333567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>0.278461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>10</td>\n",
       "      <td>0.270622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>50</td>\n",
       "      <td>0.232155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>100</td>\n",
       "      <td>0.219350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.621410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.469668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.453488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Learning Rate  Iterations      Loss\n",
       "0         0.0001          10  0.659877\n",
       "1         0.0001          50  0.333567\n",
       "2         0.0001         100  0.278461\n",
       "3         0.0010          10  0.270622\n",
       "4         0.0010          50  0.232155\n",
       "5         0.0010         100  0.219350\n",
       "6         0.0100          10  0.621410\n",
       "7         0.0100          50  0.469668\n",
       "8         0.0100         100  0.453488"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "#2\n",
    "lr_col = []\n",
    "iter_col = []\n",
    "loss_col = []\n",
    "for alpha in [.0001, .001, .01]:\n",
    "    for max_iter in [10, 50, 100]:\n",
    "        model = LogisticRegressionGD(alpha = alpha, max_iter = max_iter)\n",
    "        model.fit(X_train, y_train)\n",
    "        lr_col.append(alpha)\n",
    "        iter_col.append(max_iter)\n",
    "        loss_col.append(log_loss(y_test, model.predict_proba(X_test)))\n",
    "        \n",
    "d = {'Learning Rate': lr_col, 'Iterations': iter_col, 'Loss': loss_col}\n",
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "70ccc5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall:</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.920938</td>\n",
       "      <td>0.908676</td>\n",
       "      <td>0.886414</td>\n",
       "      <td>0.897407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.927889</td>\n",
       "      <td>0.915909</td>\n",
       "      <td>0.897550</td>\n",
       "      <td>0.906637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.905300</td>\n",
       "      <td>0.927136</td>\n",
       "      <td>0.821826</td>\n",
       "      <td>0.871311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.874023</td>\n",
       "      <td>0.924581</td>\n",
       "      <td>0.737194</td>\n",
       "      <td>0.820322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alpha  Accuracy  Precision   Recall:        F1\n",
       "0  0.0001  0.920938   0.908676  0.886414  0.897407\n",
       "1  0.0010  0.927889   0.915909  0.897550  0.906637\n",
       "2  0.0050  0.905300   0.927136  0.821826  0.871311\n",
       "3  0.0100  0.874023   0.924581  0.737194  0.820322"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2\n",
    "# Report metrics after 100 iterations with varying learning rates\n",
    "\n",
    "col_alpha = []\n",
    "col_acc = []\n",
    "col_prec = []\n",
    "col_recall = []\n",
    "col_f1 = []\n",
    "for alpha in [.0001, .001, .005, .01]:\n",
    "    model = LogisticRegressionGD(alpha = alpha, max_iter = 100)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    col_alpha.append(alpha)\n",
    "    col_acc.append(accuracy)\n",
    "    col_prec.append(precision)\n",
    "    col_recall.append(recall)\n",
    "    col_f1.append(f1)\n",
    "    \n",
    "d = {'alpha': col_alpha, 'Accuracy': col_acc, 'Precision': col_prec, 'Recall:' : col_recall, 'F1': col_f1}\n",
    "metrics_df = pd.DataFrame(d)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2c6b884f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 5}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.901449</td>\n",
       "      <td>0.098551</td>\n",
       "      <td>0.878587</td>\n",
       "      <td>0.871698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.905217</td>\n",
       "      <td>0.094783</td>\n",
       "      <td>0.888749</td>\n",
       "      <td>0.869479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0.902899</td>\n",
       "      <td>0.097101</td>\n",
       "      <td>0.889114</td>\n",
       "      <td>0.862896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0.904348</td>\n",
       "      <td>0.095652</td>\n",
       "      <td>0.896071</td>\n",
       "      <td>0.858484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0.900870</td>\n",
       "      <td>0.099130</td>\n",
       "      <td>0.895463</td>\n",
       "      <td>0.848963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>0.896522</td>\n",
       "      <td>0.103478</td>\n",
       "      <td>0.900072</td>\n",
       "      <td>0.830632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k  accuracy     error  precision    recall\n",
       "0   3  0.901449  0.098551   0.878587  0.871698\n",
       "1   5  0.905217  0.094783   0.888749  0.869479\n",
       "2   7  0.902899  0.097101   0.889114  0.862896\n",
       "3   9  0.904348  0.095652   0.896071  0.858484\n",
       "4  11  0.900870  0.099130   0.895463  0.848963\n",
       "5  15  0.896522  0.103478   0.900072  0.830632"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3a\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lda_model = LinearDiscriminantAnalysis()\n",
    "\n",
    "k_vals = [3,5,7,9,11,15]\n",
    "grid_parameters = { 'n_neighbors': k_vals}  # which parameters should be tested\n",
    "gridsearch_cv = GridSearchCV(KNeighborsClassifier(), grid_parameters, scoring=['accuracy', 'precision', 'recall'], refit='accuracy', cv=5)\n",
    "gridsearch_cv.fit(X_train, y_train)\n",
    "print(gridsearch_cv.best_params_)  # This tells you the best parameter choice\n",
    "# Create data for making a DataFrame for displaying results\n",
    "d = {'k': k_vals,\n",
    "     'accuracy': gridsearch_cv.cv_results_['mean_test_accuracy'],\n",
    "     'error': 1-gridsearch_cv.cv_results_['mean_test_accuracy'],\n",
    "     'precision': gridsearch_cv.cv_results_['mean_test_precision'],\n",
    "     'recall': gridsearch_cv.cv_results_['mean_test_recall']}\n",
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f9889d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Data</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kNN</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.932174</td>\n",
       "      <td>0.918519</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kNN</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.896612</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.928116</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.886364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.929626</td>\n",
       "      <td>0.912556</td>\n",
       "      <td>0.906459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LDA</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.885507</td>\n",
       "      <td>0.918755</td>\n",
       "      <td>0.779326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LDA</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.892268</td>\n",
       "      <td>0.915601</td>\n",
       "      <td>0.797327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model      Data  Accuracy  Precision    Recall\n",
       "0                  kNN  Training  0.932174   0.918519  0.909091\n",
       "1                  kNN   Testing  0.896612   0.875000  0.857461\n",
       "2  Logistic Regression  Training  0.928116   0.928571  0.886364\n",
       "3  Logistic Regression   Testing  0.929626   0.912556  0.906459\n",
       "4                  LDA  Training  0.885507   0.918755  0.779326\n",
       "5                  LDA   Testing  0.892268   0.915601  0.797327"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3b\n",
    "model_col = []\n",
    "data_col = []\n",
    "acc_col = []\n",
    "prec_col = []\n",
    "recall_col = []\n",
    "estimators = {'kNN' : KNeighborsClassifier(n_neighbors=5),\n",
    "              'Logistic Regression': LogisticRegression(),\n",
    "             'LDA': LinearDiscriminantAnalysis() }\n",
    "for name, model in estimators.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    for (data_name, data_x, data_y) in [('Training', X_train, y_train), ('Testing', X_test, y_test)]:\n",
    "        y_pred = model.predict(data_x)\n",
    "        accuracy = accuracy_score(data_y, y_pred)\n",
    "        precision = precision_score(data_y, y_pred)\n",
    "        recall = recall_score(data_y, y_pred)\n",
    "        f1 = f1_score(data_y, y_pred)\n",
    "        model_col.append(name)\n",
    "        data_col.append(data_name)\n",
    "        acc_col.append(accuracy)\n",
    "        prec_col.append(precision)\n",
    "        recall_col.append(recall)\n",
    "        \n",
    "d = {'Model': model_col, 'Data': data_col, 'Accuracy': acc_col, 'Precision': prec_col, 'Recall': recall_col}\n",
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "84da4519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#3c\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "probs = log_model.predict_proba(X_test)\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, probs[:,1])\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=auc, estimator_name='auc')\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "78ed7a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#3d\n",
    "from sklearn.metrics import recall_score\n",
    "fprs = []\n",
    "tprs = []\n",
    "\n",
    "model = LogisticRegression(max_iter=10000).fit(X_train, y_train)\n",
    "probs = model.predict_proba(X_test)\n",
    "for t in [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]:\n",
    "    y_pred_t = np.where(probs[:, 1] >= t, 1, 0)\n",
    "    tpr = recall_score(y_test, y_pred_t)\n",
    "    fpr = 1 - recall_score(y_test, y_pred_t, pos_label = 0)\n",
    "    fprs.append(fpr)\n",
    "    tprs.append(tpr)\n",
    "plt.plot(fprs, tprs)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8d4b360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "#4a\n",
    "def kfold_cv(X_data, y_data, model, splits):\n",
    "    errors = []\n",
    "    kf = KFold(n_splits=splits)\n",
    "    kf.get_n_splits(X_data)\n",
    "    for train_index, test_index in kf.split(X_data):\n",
    "        x_train_kf = X_train.iloc[train_index]\n",
    "        x_test_kf = X_train.iloc[test_index]\n",
    "        y_train_kf = y_train.iloc[train_index]\n",
    "        y_test_kf = y_train.iloc[test_index]\n",
    "        model.fit(x_train_kf, y_train_kf)\n",
    "        y_pred_kf = model.predict(x_test_kf)\n",
    "        acc = accuracy_score(y_test_kf, y_pred_kf)\n",
    "        err = 1 - acc\n",
    "        errors.append(err)\n",
    "    result = {'avg_err': np.mean(errors), 'error': errors}\n",
    "    print(f'average error: {np.mean(errors)}')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3833a138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average error: 0.07971014492753623\n",
      "average error: 0.07681159420289857\n",
      "average error: 0.11391304347826085\n",
      "average error: 0.11391304347826085\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>k</th>\n",
       "      <th>Avg Validation Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5</td>\n",
       "      <td>0.079710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>10</td>\n",
       "      <td>0.076812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LDA</td>\n",
       "      <td>5</td>\n",
       "      <td>0.113913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LDA</td>\n",
       "      <td>10</td>\n",
       "      <td>0.113913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model   k  Avg Validation Error\n",
       "0  Logistic Regression   5              0.079710\n",
       "1  Logistic Regression  10              0.076812\n",
       "2                  LDA   5              0.113913\n",
       "3                  LDA  10              0.113913"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4b\n",
    "k_col = []\n",
    "err_col = []\n",
    "model_col = []\n",
    "estimators = {'Logistic Regression': LogisticRegression(),\n",
    "             'LDA': LinearDiscriminantAnalysis() }\n",
    "for name, model in estimators.items():\n",
    "    for k in [5, 10]:\n",
    "        result = kfold_cv(X_train, y_train, model, k)\n",
    "        avg_err = result['avg_err']\n",
    "        k_col.append(k)\n",
    "        err_col.append(avg_err)\n",
    "        model_col.append(name)\n",
    "        errors = result['error']\n",
    "\n",
    "d = {'Model': model_col, 'k': k_col, 'Avg Validation Error': err_col}\n",
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ffeda3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58ea94a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b06546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
