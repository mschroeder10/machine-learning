{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98816da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a098a60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.142</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.555</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.404</td>\n",
       "      <td>6</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.147</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4601 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0               0.00               0.64           0.64           0.0   \n",
       "1               0.21               0.28           0.50           0.0   \n",
       "2               0.06               0.00           0.71           0.0   \n",
       "3               0.00               0.00           0.00           0.0   \n",
       "4               0.00               0.00           0.00           0.0   \n",
       "...              ...                ...            ...           ...   \n",
       "4596            0.31               0.00           0.62           0.0   \n",
       "4597            0.00               0.00           0.00           0.0   \n",
       "4598            0.30               0.00           0.30           0.0   \n",
       "4599            0.96               0.00           0.00           0.0   \n",
       "4600            0.00               0.00           0.65           0.0   \n",
       "\n",
       "      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0              0.32            0.00              0.00                0.00   \n",
       "1              0.14            0.28              0.21                0.07   \n",
       "2              1.23            0.19              0.19                0.12   \n",
       "3              0.63            0.00              0.31                0.63   \n",
       "4              0.63            0.00              0.31                0.63   \n",
       "...             ...             ...               ...                 ...   \n",
       "4596           0.00            0.31              0.00                0.00   \n",
       "4597           0.00            0.00              0.00                0.00   \n",
       "4598           0.00            0.00              0.00                0.00   \n",
       "4599           0.32            0.00              0.00                0.00   \n",
       "4600           0.00            0.00              0.00                0.00   \n",
       "\n",
       "      word_freq_order  word_freq_mail  ...  char_freq_;   char_freq_(   \\\n",
       "0                0.00            0.00  ...         0.000         0.000   \n",
       "1                0.00            0.94  ...         0.000         0.132   \n",
       "2                0.64            0.25  ...         0.010         0.143   \n",
       "3                0.31            0.63  ...         0.000         0.137   \n",
       "4                0.31            0.63  ...         0.000         0.135   \n",
       "...               ...             ...  ...           ...           ...   \n",
       "4596             0.00            0.00  ...         0.000         0.232   \n",
       "4597             0.00            0.00  ...         0.000         0.000   \n",
       "4598             0.00            0.00  ...         0.102         0.718   \n",
       "4599             0.00            0.00  ...         0.000         0.057   \n",
       "4600             0.00            0.00  ...         0.000         0.000   \n",
       "\n",
       "      char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0             0.0        0.778        0.000        0.000   \n",
       "1             0.0        0.372        0.180        0.048   \n",
       "2             0.0        0.276        0.184        0.010   \n",
       "3             0.0        0.137        0.000        0.000   \n",
       "4             0.0        0.135        0.000        0.000   \n",
       "...           ...          ...          ...          ...   \n",
       "4596          0.0        0.000        0.000        0.000   \n",
       "4597          0.0        0.353        0.000        0.000   \n",
       "4598          0.0        0.000        0.000        0.000   \n",
       "4599          0.0        0.000        0.000        0.000   \n",
       "4600          0.0        0.125        0.000        0.000   \n",
       "\n",
       "      capital_run_length_average  capital_run_length_longest  \\\n",
       "0                          3.756                          61   \n",
       "1                          5.114                         101   \n",
       "2                          9.821                         485   \n",
       "3                          3.537                          40   \n",
       "4                          3.537                          40   \n",
       "...                          ...                         ...   \n",
       "4596                       1.142                           3   \n",
       "4597                       1.555                           4   \n",
       "4598                       1.404                           6   \n",
       "4599                       1.147                           5   \n",
       "4600                       1.250                           5   \n",
       "\n",
       "      capital_run_length_total  spam  \n",
       "0                          278     1  \n",
       "1                         1028     1  \n",
       "2                         2259     1  \n",
       "3                          191     1  \n",
       "4                          191     1  \n",
       "...                        ...   ...  \n",
       "4596                        88     0  \n",
       "4597                        14     0  \n",
       "4598                       118     0  \n",
       "4599                        78     0  \n",
       "4600                        40     0  \n",
       "\n",
       "[4601 rows x 58 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['word_freq_make','word_freq_address', 'word_freq_all','word_freq_3d','word_freq_our','word_freq_over',\n",
    "         'word_freq_remove','word_freq_internet','word_freq_order','word_freq_mail','word_freq_receive','word_freq_will',\n",
    "         'word_freq_people','word_freq_report','word_freq_addresses','word_freq_free','word_freq_business','word_freq_email',\n",
    "         'word_freq_you','word_freq_credit','word_freq_your','word_freq_font','word_freq_000','word_freq_money','word_freq_hp',\n",
    "         'word_freq_hpl','word_freq_george','word_freq_650','word_freq_lab','word_freq_labs','word_freq_telnet','word_freq_857',\n",
    "         'word_freq_data','word_freq_415','word_freq_85','word_freq_technology','word_freq_1999','word_freq_parts','word_freq_pm',\n",
    "         'word_freq_direct','word_freq_cs','word_freq_meeting','word_freq_original','word_freq_project','word_freq_re','word_freq_edu',\n",
    "         'word_freq_table','word_freq_conference','char_freq_; ','char_freq_( ','char_freq_[','char_freq_!','char_freq_$','char_freq_#',\n",
    "        'capital_run_length_average','capital_run_length_longest','capital_run_length_total', 'spam']\n",
    "df = pd.read_csv('spambase.data', names=cols)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a7a85b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "features = df.loc[:,df.columns != 'spam']\n",
    "target = df.loc[:, 'spam']\n",
    "# Split into training/testing\n",
    "# The following will split as 75% training 25% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.25, random_state=3000)\n",
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a3c8c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format a number based on its magnitude\n",
    "# If <= 100000, print using :.3f\n",
    "# Else print using :.0e\n",
    "def format_nbr(f):\n",
    "    if abs(f) < 100000:\n",
    "        return f'{f:.3f}'\n",
    "    else:\n",
    "        return f'{f:.4e}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c09c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1a train logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train, y_train)\n",
    "y_test_predicted = log_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50224780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   confusion matrix =\n",
      " [[663  39]\n",
      " [ 42 407]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#1a conf matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_test_predicted)\n",
    "print(f'   confusion matrix =\\n {conf_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8861154e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true positives =  407,\n",
      "false positives = 39,\n",
      "true negatives = 663,\n",
      "false negatives = 42\n"
     ]
    }
   ],
   "source": [
    "#1a tn, fp, fn, tp\n",
    "tn, fp, fn, tp = conf_matrix.ravel() \n",
    "print (f'true positives =  {tp},\\nfalse positives = {fp},\\ntrue negatives = {tn},\\nfalse negatives = {fn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efd40b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy = 0.930\n",
      "   error = 0.070\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#1a acc/error \n",
    "acc = accuracy_score(y_test, y_test_predicted)\n",
    "err = 1-acc\n",
    "print(f'   accuracy = {format_nbr(acc)}')\n",
    "print(f'   error = {format_nbr(err)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b406b0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   precision = 0.913\n",
      "   recall = 0.906\n",
      "   f1 = 0.909\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#1a prec, recall, f1\n",
    "prec= precision_score(y_test, y_test_predicted)\n",
    "recall = recall_score(y_test, y_test_predicted)\n",
    "f1 = f1_score(y_test, y_test_predicted)\n",
    "print(f'   precision = {format_nbr(prec)}')\n",
    "print(f'   recall = {format_nbr(recall)}')\n",
    "print(f'   f1 = {format_nbr(f1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3be8478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature      Coef\n",
      "55  capital_run_length_longest  1.267732\n",
      "52                 char_freq_$  1.207775\n",
      "6             word_freq_remove  0.895562\n",
      "22               word_freq_000  0.894307\n",
      "3                 word_freq_3d  0.864112\n",
      "53                 char_freq_#  0.858514\n",
      "15              word_freq_free  0.821593\n",
      "19            word_freq_credit  0.569852\n",
      "56    capital_run_length_total  0.443533\n",
      "4                word_freq_our  0.396171\n",
      "16          word_freq_business  0.386323\n",
      "23             word_freq_money  0.361201\n",
      "35        word_freq_technology  0.290619\n",
      "51                 char_freq_!  0.248957\n",
      "27               word_freq_650  0.238475\n",
      "20              word_freq_your  0.237265\n",
      "21              word_freq_font  0.227725\n",
      "5               word_freq_over  0.191943\n",
      "7           word_freq_internet  0.191727\n",
      "8              word_freq_order  0.178446\n",
      "31               word_freq_857  0.162189\n",
      "18               word_freq_you  0.161183\n",
      "14         word_freq_addresses  0.132030\n",
      "17             word_freq_email  0.096326\n",
      "2                word_freq_all  0.077128\n",
      "13            word_freq_report  0.066924\n",
      "9               word_freq_mail  0.062902\n",
      "36              word_freq_1999  0.002406\n",
      "10           word_freq_receive -0.017561\n",
      "12            word_freq_people -0.022277\n",
      "0               word_freq_make -0.062459\n",
      "50                 char_freq_[ -0.069315\n",
      "49                char_freq_(  -0.119270\n",
      "37             word_freq_parts -0.131000\n",
      "11              word_freq_will -0.142506\n",
      "46             word_freq_table -0.178525\n",
      "1            word_freq_address -0.216185\n",
      "29              word_freq_labs -0.236895\n",
      "39            word_freq_direct -0.238364\n",
      "42          word_freq_original -0.287974\n",
      "48                char_freq_;  -0.309355\n",
      "54  capital_run_length_average -0.328625\n",
      "30            word_freq_telnet -0.370172\n",
      "38                word_freq_pm -0.413348\n",
      "32              word_freq_data -0.497956\n",
      "44                word_freq_re -0.732016\n",
      "47        word_freq_conference -0.810440\n",
      "25               word_freq_hpl -0.897575\n",
      "43           word_freq_project -0.925207\n",
      "45               word_freq_edu -1.169913\n",
      "33               word_freq_415 -1.207919\n",
      "34                word_freq_85 -1.251728\n",
      "41           word_freq_meeting -1.297299\n",
      "28               word_freq_lab -1.359462\n",
      "40                word_freq_cs -1.655612\n",
      "24                word_freq_hp -2.277950\n",
      "26            word_freq_george -3.912352\n"
     ]
    }
   ],
   "source": [
    "#1b print coeffs \n",
    "# Make a dataframe with first column naming features and 2nd column the coefficient for that feature\n",
    "d = {'feature': cols[:-1], 'Coef': log_model.coef_[0]}\n",
    "df_coef = pd.DataFrame(data = d)\n",
    "# Sort the coefficient dataframe to see which are largest (both positive and negative)\n",
    "df_coef_sorted = df_coef.sort_values('Coef', ascending=False)\n",
    "print(df_coef_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2de3a900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.898349</td>\n",
       "      <td>0.810861</td>\n",
       "      <td>0.964365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.929626</td>\n",
       "      <td>0.912556</td>\n",
       "      <td>0.906459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.903562</td>\n",
       "      <td>0.947090</td>\n",
       "      <td>0.797327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.847958</td>\n",
       "      <td>0.962838</td>\n",
       "      <td>0.634744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      T  Accuracy  Precision   Recall:\n",
       "0  0.25  0.898349   0.810861  0.964365\n",
       "1  0.50  0.929626   0.912556  0.906459\n",
       "2  0.75  0.903562   0.947090  0.797327\n",
       "3  0.90  0.847958   0.962838  0.634744"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1c\n",
    "probs = log_model.predict_proba(X_test)\n",
    "col_t = []\n",
    "col_acc = []\n",
    "col_prec = []\n",
    "col_recall = []\n",
    "for t in [0.25, 0.5, 0.75, 0.9]:\n",
    "    y_pred_t = np.where(probs[:, 1] >= t, 1, 0)\n",
    "    accuracy = accuracy_score(y_test, y_pred_t)\n",
    "    prec= precision_score(y_test, y_pred_t)\n",
    "    recall = recall_score(y_test, y_pred_t)\n",
    "    col_t.append(t)\n",
    "    col_acc.append(accuracy)\n",
    "    col_prec.append(prec)\n",
    "    col_recall.append(recall)\n",
    "    \n",
    "d = {'T': col_t, 'Accuracy': col_acc, 'Precision': col_prec, 'Recall:' : col_recall}\n",
    "metrics_df = pd.DataFrame(d)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78119ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 gradient descent\n",
    "from numpy.linalg import norm\n",
    "class LogisticRegressionGD:\n",
    "    def __init__(self, alpha, epsilon = .01, max_iter=1000):\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "        self.max_iter = max_iter\n",
    "        self.theta_ = []\n",
    "       \n",
    "    def loss(self, h, y):\n",
    "        h = np.maximum(h, 1.0e-9)\n",
    "        h = np.minimum(h, 1 - 1.0e-9)\n",
    "        return - (y @ np.log(h) + (1 - y)@np.log(1 - h))\n",
    "    \n",
    "    def h_theta(self, X, theta):\n",
    "        z = X @ theta\n",
    "        # Protect against exp(-z) blowing up and causing a warning\n",
    "        z = np.maximum(-1.0E2, z)\n",
    "        h = 1 / (1 + np.exp(-z))\n",
    "        return h\n",
    "\n",
    "    # fits the model to the training data\n",
    "    def fit(self, X, y):\n",
    "        X_arr = np.insert(X.to_numpy(), 0, 1, axis=1)\n",
    "        # Initialize random theta\n",
    "        self.theta_ = np.random.rand(X_arr.shape[1])\n",
    "       \n",
    "        for i in range(0, self.max_iter):\n",
    "            h = self.h_theta(X_arr, self.theta_)\n",
    "            self.cross_entropy_loss = self.loss(h, y)\n",
    "            theta_new = self.theta_ - self.alpha * (h - y).transpose() @ X_arr\n",
    "            delta = np.linalg.norm(theta_new - self.theta_)\n",
    "            self.theta_ = theta_new\n",
    "            if delta < self.epsilon:\n",
    "                break\n",
    "        # Save instance variables used by run_model method\n",
    "        self.coef_ = self.theta_[1:]\n",
    "        self.intercept_ = self.theta_[0]\n",
    "\n",
    "    # Predict Y values given X values using model fit\n",
    "    def predict(self, X):\n",
    "        X2 = np.insert(X.to_numpy(), 0, 1, axis=1)\n",
    "        probs = self.h_theta(X2, self.theta_)\n",
    "        result = np.where(probs >= 0.5, 1, 0)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8dca74c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Iterations</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>10</td>\n",
       "      <td>2244.928960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>1105.435251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>890.638317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>10</td>\n",
       "      <td>900.562552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>50</td>\n",
       "      <td>782.567384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>100</td>\n",
       "      <td>750.725920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>10</td>\n",
       "      <td>1138.047799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>50</td>\n",
       "      <td>1605.060981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>100</td>\n",
       "      <td>1546.107014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Learning Rate  Iterations         Loss\n",
       "0         0.0001          10  2244.928960\n",
       "1         0.0001          50  1105.435251\n",
       "2         0.0001         100   890.638317\n",
       "3         0.0010          10   900.562552\n",
       "4         0.0010          50   782.567384\n",
       "5         0.0010         100   750.725920\n",
       "6         0.0100          10  1138.047799\n",
       "7         0.0100          50  1605.060981\n",
       "8         0.0100         100  1546.107014"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2\n",
    "lr_col = []\n",
    "iter_col = []\n",
    "loss_col = []\n",
    "for alpha in [.0001, .001, .01]:\n",
    "    for max_iter in [10, 50, 100]:\n",
    "        model = LogisticRegressionGD(alpha = alpha, max_iter = max_iter)\n",
    "        model.fit(X_train, y_train)\n",
    "        lr_col.append(alpha)\n",
    "        iter_col.append(max_iter)\n",
    "        loss_col.append(model.cross_entropy_loss)\n",
    "        #print(f'Iterations: {max_iter}, Learning rate: {alpha}, Cross-entropy loss: {model.cross_entropy_loss:.4f}')\n",
    "        \n",
    "d = {'Learning Rate': lr_col, 'Iterations': iter_col, 'Loss': loss_col}\n",
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "70ccc5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall:</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.914857</td>\n",
       "      <td>0.905312</td>\n",
       "      <td>0.873051</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.927889</td>\n",
       "      <td>0.915909</td>\n",
       "      <td>0.897550</td>\n",
       "      <td>0.906637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.913988</td>\n",
       "      <td>0.845850</td>\n",
       "      <td>0.953229</td>\n",
       "      <td>0.896335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.877498</td>\n",
       "      <td>0.925414</td>\n",
       "      <td>0.746102</td>\n",
       "      <td>0.826141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alpha  Accuracy  Precision   Recall:        F1\n",
       "0  0.0001  0.914857   0.905312  0.873051  0.888889\n",
       "1  0.0010  0.927889   0.915909  0.897550  0.906637\n",
       "2  0.0050  0.913988   0.845850  0.953229  0.896335\n",
       "3  0.0100  0.877498   0.925414  0.746102  0.826141"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2\n",
    "# Report metrics after 100 iterations with varying learning rates\n",
    "\n",
    "col_alpha = []\n",
    "col_acc = []\n",
    "col_prec = []\n",
    "col_recall = []\n",
    "col_f1 = []\n",
    "for alpha in [.0001, .001, .005, .01]:\n",
    "    model = LogisticRegressionGD(alpha = alpha, max_iter = 100)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    col_alpha.append(alpha)\n",
    "    col_acc.append(accuracy)\n",
    "    col_prec.append(precision)\n",
    "    col_recall.append(recall)\n",
    "    col_f1.append(f1)\n",
    "    \n",
    "d = {'alpha': col_alpha, 'Accuracy': col_acc, 'Precision': col_prec, 'Recall:' : col_recall, 'F1': col_f1}\n",
    "metrics_df = pd.DataFrame(d)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c6b884f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 5}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.901449</td>\n",
       "      <td>0.098551</td>\n",
       "      <td>0.878587</td>\n",
       "      <td>0.871698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.905217</td>\n",
       "      <td>0.094783</td>\n",
       "      <td>0.888749</td>\n",
       "      <td>0.869479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0.902899</td>\n",
       "      <td>0.097101</td>\n",
       "      <td>0.889114</td>\n",
       "      <td>0.862896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0.904348</td>\n",
       "      <td>0.095652</td>\n",
       "      <td>0.896071</td>\n",
       "      <td>0.858484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0.900870</td>\n",
       "      <td>0.099130</td>\n",
       "      <td>0.895463</td>\n",
       "      <td>0.848963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>0.896522</td>\n",
       "      <td>0.103478</td>\n",
       "      <td>0.900072</td>\n",
       "      <td>0.830632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k  accuracy     error  precision    recall\n",
       "0   3  0.901449  0.098551   0.878587  0.871698\n",
       "1   5  0.905217  0.094783   0.888749  0.869479\n",
       "2   7  0.902899  0.097101   0.889114  0.862896\n",
       "3   9  0.904348  0.095652   0.896071  0.858484\n",
       "4  11  0.900870  0.099130   0.895463  0.848963\n",
       "5  15  0.896522  0.103478   0.900072  0.830632"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3a\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lda_model = LinearDiscriminantAnalysis()\n",
    "\n",
    "k_vals = [3,5,7,9,11,15]\n",
    "grid_parameters = { 'n_neighbors': k_vals}  # which parameters should be tested\n",
    "gridsearch_cv = GridSearchCV(KNeighborsClassifier(), grid_parameters, scoring=['accuracy', 'precision', 'recall'], refit='accuracy', cv=5)\n",
    "gridsearch_cv.fit(X_train, y_train)\n",
    "print(gridsearch_cv.best_params_)  # This tells you the best parameter choice\n",
    "# Create data for making a DataFrame for displaying results\n",
    "d = {'k': k_vals,\n",
    "     'accuracy': gridsearch_cv.cv_results_['mean_test_accuracy'],\n",
    "     'error': 1-gridsearch_cv.cv_results_['mean_test_accuracy'],\n",
    "     'precision': gridsearch_cv.cv_results_['mean_test_precision'],\n",
    "     'recall': gridsearch_cv.cv_results_['mean_test_recall']}\n",
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9889d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Data</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kNN</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.932174</td>\n",
       "      <td>0.918519</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kNN</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.896612</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.928116</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.886364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.929626</td>\n",
       "      <td>0.912556</td>\n",
       "      <td>0.906459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LDA</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.885507</td>\n",
       "      <td>0.918755</td>\n",
       "      <td>0.779326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LDA</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.892268</td>\n",
       "      <td>0.915601</td>\n",
       "      <td>0.797327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model      Data  Accuracy  Precision    Recall\n",
       "0                  kNN  Training  0.932174   0.918519  0.909091\n",
       "1                  kNN   Testing  0.896612   0.875000  0.857461\n",
       "2  Logistic Regression  Training  0.928116   0.928571  0.886364\n",
       "3  Logistic Regression   Testing  0.929626   0.912556  0.906459\n",
       "4                  LDA  Training  0.885507   0.918755  0.779326\n",
       "5                  LDA   Testing  0.892268   0.915601  0.797327"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3b\n",
    "model_col = []\n",
    "data_col = []\n",
    "acc_col = []\n",
    "prec_col = []\n",
    "recall_col = []\n",
    "estimators = {'kNN' : KNeighborsClassifier(n_neighbors=5),\n",
    "              'Logistic Regression': LogisticRegression(),\n",
    "             'LDA': LinearDiscriminantAnalysis() }\n",
    "for name, model in estimators.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    for (data_name, data_x, data_y) in [('Training', X_train, y_train), ('Testing', X_test, y_test)]:\n",
    "        y_pred = model.predict(data_x)\n",
    "        accuracy = accuracy_score(data_y, y_pred)\n",
    "        precision = precision_score(data_y, y_pred)\n",
    "        recall = recall_score(data_y, y_pred)\n",
    "        f1 = f1_score(data_y, y_pred)\n",
    "        model_col.append(name)\n",
    "        data_col.append(data_name)\n",
    "        acc_col.append(accuracy)\n",
    "        prec_col.append(precision)\n",
    "        recall_col.append(recall)\n",
    "        \n",
    "d = {'Model': model_col, 'Data': data_col, 'Accuracy': acc_col, 'Precision': prec_col, 'Recall': recall_col}\n",
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84da4519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#3c\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "probs = log_model.predict_proba(X_test)\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, probs[:,1])\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=auc, estimator_name='auc')\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78ed7a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#3d\n",
    "from sklearn.metrics import recall_score\n",
    "fprs = []\n",
    "tprs = []\n",
    "\n",
    "model = LogisticRegression(max_iter=10000).fit(X_train, y_train)\n",
    "probs = model.predict_proba(X_test)\n",
    "for t in np.arange(0, 1.01, .005):\n",
    "    y_pred_t = np.where(probs[:, 1] >= t, 1, 0)\n",
    "    tpr = recall_score(y_test, y_pred_t)\n",
    "    fpr = 1 - recall_score(y_test, y_pred_t, pos_label = 0)\n",
    "    fprs.append(fpr)\n",
    "    tprs.append(tpr)\n",
    "plt.plot(fprs, tprs)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d4b360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "#4a\n",
    "def kfold_cv(X_data, y_data, model, splits):\n",
    "    errors = []\n",
    "    kf = KFold(n_splits=splits)\n",
    "    kf.get_n_splits(X_data)\n",
    "    for train_index, test_index in kf.split(X_data):\n",
    "        x_train_kf = X_train.iloc[train_index]\n",
    "        x_test_kf = X_train.iloc[test_index]\n",
    "        y_train_kf = y_train.iloc[train_index]\n",
    "        y_test_kf = y_train.iloc[test_index]\n",
    "        model.fit(x_train_kf, y_train_kf)\n",
    "        y_pred_kf = model.predict(x_test_kf)\n",
    "        acc = accuracy_score(y_test_kf, y_pred_kf)\n",
    "        err = 1 - acc\n",
    "        errors.append(err)\n",
    "    result = {'avg_err': np.mean(errors), 'error': errors}\n",
    "    print(f'average error: {np.mean(errors)}')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3833a138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average error: 0.07971014492753623\n",
      "average error: 0.07681159420289857\n",
      "average error: 0.11391304347826085\n",
      "average error: 0.11391304347826085\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>k</th>\n",
       "      <th>Avg Validation Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5</td>\n",
       "      <td>0.079710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>10</td>\n",
       "      <td>0.076812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LDA</td>\n",
       "      <td>5</td>\n",
       "      <td>0.113913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LDA</td>\n",
       "      <td>10</td>\n",
       "      <td>0.113913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model   k  Avg Validation Error\n",
       "0  Logistic Regression   5              0.079710\n",
       "1  Logistic Regression  10              0.076812\n",
       "2                  LDA   5              0.113913\n",
       "3                  LDA  10              0.113913"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4b\n",
    "k_col = []\n",
    "err_col = []\n",
    "model_col = []\n",
    "estimators = {'Logistic Regression': LogisticRegression(),\n",
    "             'LDA': LinearDiscriminantAnalysis() }\n",
    "for name, model in estimators.items():\n",
    "    for k in [5, 10]:\n",
    "        result = kfold_cv(X_train, y_train, model, k)\n",
    "        avg_err = result['avg_err']\n",
    "        k_col.append(k)\n",
    "        err_col.append(avg_err)\n",
    "        model_col.append(name)\n",
    "        errors = result['error']\n",
    "\n",
    "d = {'Model': model_col, 'k': k_col, 'Avg Validation Error': err_col}\n",
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ffeda3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58ea94a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b06546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
